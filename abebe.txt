Abstract

Since the 1960s, databases have been faster thanks to query processing and optimization techniques. The standard techniques include rule based and cost based optimizations. But beyond those, many techniques have been developed and are being researched over the years. It was observed that most techniques find optimizations based on specific situations rather than creating efficiencies in all situations. Applications of these added efficiencies affect industries that often use big data including the finance industry, retail industry, etc. We believe that there are more techniques yet to come, and more industry applications that follow.



Introduction

The following is a report on our research on advancements in query processing and optimizations. Our observations, and later our conclusions have been stated. Query processing is the actions that a database management system takes to return results for a query. Query optimization is a step in query processing focusing on deriving an efficient way of executing the query. We investigate the basic concepts in this topic, explore several advancements in query processing and query optimization, discuss applications in the industry, and finally, express our overall understanding and opinion on the subject. We did a literature review on existing research articles and websites.

1. Overview

1.1 Definitions

A query is a request sent to a database management system to get data. It is often initially expressed in a high level declarative language (such as SQL) informing the database management system what data to extract, but not how to extract it. It is later translated into lower level operations and executed.

Query processing refers to the steps taken by a database management system to accept queries and return results. It has three steps:

Parsing and translating queries into relational algebra
Query optimization to create an efficient execution plan
Evaluation and returning results
Query optimization is a component of query processing. Queries written in a declarative syntax have many equivalent ways to be executed. This process tries to find an efficient, if not the most efficient, execution plan.

1.2 Goals and Benefits

Efficient query processing and optimization techniques lead to the following benefits:

Faster response times: These techniques help a database process queries in less time so that the query caller gets results quickly.
Usage of fewer resources: Hardware and network related resources are used more efficiently so that more can be done with fewer resources. 
Less cost: When databases efficiently process queries, they have more room for scalability. For example, they can handle responding to more queries concurrently. This can result in less cost spent on adding new hardware to scale.
1.3 Evolution of Advancements

Research on query processing and optimization techniques started in the 1970s. The sophistication of these techniques has been growing ever since. At first, these optimization techniques focused on finding efficient execution plans in a single processor environment. Later, more sophisticated approaches including taking advantage of parallel processors, distributed environments, and large scale environments started to appear.

The driving factors for these sophisticated advancements include:

Growing data and storage complexity: With the explosion of big data, large amounts of unstructured data are stored. This volume and loose structure pose new challenges that are not addressed by traditional techniques.
Advances in hardware: Modern computers are often equipped with multi core CPUs. They are also equipped with GPUs. Database management systems take advantage of them for better performance, introducing more sophistication to the traditional techniques.
Machine learning related innovations: Machine learning optimization techniques that take advantage of historical data and query patterns are sometimes more beneficial than traditional alternatives. They can better predict query costs and choose more optimal execution plans. 
Cloud computing: The shift to cloud computing in recent years has pushed the creation of new optimization techniques that operate on scalable distributed environments.
Core Concepts for Query Processing and Optimization
2.1 Query Processing Life Cycle

The main steps in query processing are:

Parsing and translation: If syntax errors exist in the query language, it is checked for. A query tree is generated. Each part of the tree represents an operation. It can be a selection, projection, or an another type of operation.
Query Optimization: Several execution strategies are generated from the query tree, and compared. Finding the most efficient plan might be costly itself, but generally, an efficient plan is selected. An execution plan is then generated. It is a ‘physical’ plan that will be later executed.
Execution: The optimized query execution plan is executed. The requested data or results are returned to the query caller.

2.2 Essential Elements

An understanding of the following key concepts helps one explore advancements in query processing and optimization techniques.

2.2.1 Relational Algebra

Relational algebra is the theoretical foundation behind relational databases. It started to gain attention in the 1970s, when it was proposed by E.F Codd to be applied on database systems. It defines operators that are used to transform input relations to output relations. These include selection, projection, join, etc. It’s important as it is the means to explore multiple equivalent queries and choose efficient ones.

2.2.2 Logical and Physical Query Plans

A logical query plan describes the relational operations needed to be executed in order to get results. It’s rather more abstract. It does not concern itself with the details of how each operation is executed.

A physical query plan describes the lower level operational details of each step in the logical query plan. It includes the methods of accessing and manipulating data.

2.2.3 Metrics of Evaluation

Advancements in query processing and optimization techniques can often be compared and contrasted with the following evaluation metrics:

Cost: An abstract measure that considers time spent in CPU computations, disk input output activities, network data transfers, etc. It also considers the amount of storage and RAM used.
Latency: A time measure that spans the moment a query is taken up to the return of results. This measure is important to consider for real time applications.
Throughput: The number of requests processed in a span of time. This measure is useful to know how concurrent query processes are as concurrency leads to higher throughput measures.
2.2.4 Basic Types of Query Optimizations

Two main types of query optimization techniques are seen, especially in the early advancements in query processing and optimization. They are:

Rule based optimization: This type of optimization is relatively simple. They tend to optimize query execution plans but often less so than other alternatives. It uses a predefined set of rules or heuristics to arrive at an optimized execution plan. For example, a good heuristic is to use indexes over a full table scan for searching. Selection operations can be processed first so that intermediate results consume less memory. This optimization technique was extensively used in the early days of databases.
Cost based optimization: Instead of general rules or heuristics, this method uses statistical information about the database. It tries to evaluate multiple plans by comparing their resource and time usage. It is often more adaptive to the conditions of the database. Its benefits are more apparent for complex queries in large datasets.
Advances in Query Processing Techniques
With time, more advanced query processing techniques have been invented to the techniques discussed earlier. They include:

3.1 Distributed Query Processing

Distributed query processing was mainly pioneered by a distributed database management system called SDD1 (System for Distributed Databases 1). It involves processing queries across databases or servers. It is common to find in cloud environments.

When a database becomes distributed, network communication between nodes becomes necessary. It can add a time cost to query processing, especially in low speed networks. Advances had to be made to make query processing efficient. Some of the major methods of optimization include:

3.1.1 Lowering the cost of data transfer

A distributed database can consist of several sites. Consider a user sending a query to site 1 (S1). The query needs data from S1, and from another site, S2. The query has three ways of execution:

S2’s data can be sent to S1 and then processed
S1’s data can be sent to S2 and then be processed
S1’s and S2’s data can be sent to another site and then be processed
The best option depends on the amount of data needed from each site and the communication cost between each site.

3.2.2 Semi Joins

A distributed database consists of several nodes. Consider a distributed database has two relations, Suppliers and Parts. Suppliers are stored at node1, and have sid, name, and city as their attributes. Parts are stored at node2, and have pid, name, and sid as their attributes. The intent is to join Suppliers and Parts. A method that can drastically reduce the network communication related cost can be the following:

Send a projection of supplier IDs (sid) to node2
Node2 joins or filters its Parts using the supplier IDs
Node2 sends the filtered subset, potentially effectively reducing the amount of data needed to be sent to Node1
In this way, semi joins reduce the amount of data sent through networks, resulting in less time to process queries.

3.2 Adaptive Query Execution

Traditional query execution is simply planned at once and then executed. However, in this technique, the database system can modify its execution plans during runtime. In the early 2020s, Apache Spark made significant advances in integrating this technique. Some optimizations enabled by this technique include:

3.2.1 Dynamic Partition Coalescing

Some queries can contain operations such as group by. Group by aggregates data based on specified columns or keys (Eg. aggregate average sales by product ID). To process these queries, systems like Spark first divide data into multiple partitions. Partitions are simply small and manageable chunks of data that can be processed. When aggregating results (during runtime), the system may observe that some partitions are significantly smaller than others. It will coalesce (merge) the small partitions into one so that the overhead of aggregating intermediate results is removed.

3.2.2 Dynamic Join Strategy 

When the Apache Spark system joins two tables, its strategies include:

Broadcast Hash Join: When one of the two tables is relatively small, it can be sent to all partitions that contain the data in the bigger table. Each partition can then execute the join operation locally. This method has a relatively efficient time consumption.
Shuffle Hash Join: If both tables are relatively large, a more sophisticated data reallocation is used. This method also allows for parallel processing, but a lot more data movement is involved. Therefore, it is not as efficient.
By dynamically knowing the table sizes at run time, the best join strategy can be used.

3.3 Federated Query Processing

Federated query engines enable one to query multiple data sources. For example, it can serve as a single front to multiple databases including relational databases, NoSQL databases, and external APIs. It’s often useful on big data related applications where multiple data sources need to be accessed. Some examples of federated query engines include Amazon Redshift and Google BigQuery. For the query processing to be efficient, some of the strategies used include:

Query decomposition and source selection: selecting the correct data sources minimizes the amount of data processed. Irrelevant data can lead to extra time spent on unnecessary data retrieval and processing.
Cost based optimization: This is often not possible as collecting statistical data on data sources is challenging.
Heuristic based optimization: Since rule based optimizations don’t require much information, they are often used in this context.
Advances in Query Optimization Techniques
4.1 Automatic Indexing

Database management systems can look into usage patterns and deduce which columns of a table should have an index. This technique allows the database to self adjust and optimize for frequently used queries. It is used by databases including ones owned by Oracle. It has roughly three steps:

Create index candidates: the database management system tries to create candidate indexes in the background. The indexes are chosen based on recent query patterns. They are marked “INVISIBLE” and “UNUSABLE”. They are not usable yet.
Validation: A subset of SQL statements is first selected. They are a subset of SQL queries that were previously captured and stored along with other useful information. First, the optimizer will check which candidate indexes would be chosen. After that, the optimizer checks if performance improvements are gained when the queries are processed.
Update indexes: If better performance is seen, the indexes are set to be visible and ready for use.
In this way, query speed can be improved without much manual intervention.

4.2 Enhanced Indexing Techniques

The standard indexing technique is called B tree indexing. This technique sorts data according to the ordering of an attribute/column. When searching for a tuple based on that column, the database management system does not have to look through all tuples. It can arrive at the needed tuple much faster using the binary search technique. However additional indexing techniques have been introduced that further optimize queries. They include:

Bitmap indexing: If the database columns have few distinct values, but the rows are frequently queried by using these columns, this technique can be very beneficial. A Bit consists of 0 and 1, which can be interpreted as True/False or Yes/No. A bit map is simply a chain of bits stored as a single unit in a computer. The presence and absence of a value in a column can be represented with a bit. For multiple columns, it can be presented with a bit map. Using bitmaps instead of traditional methods allows for faster querying while occupying much less space for index storage. This happens because it allows for querying the row in a single step instead of checking each column individually.
Full text indexing: This technique is often used when searching all text found in a database. Without this technique, a word search may require processing all text in the database. If the amount of text is huge, it can be an inefficient process. However, with full text indexing, words are first extracted from the database. After that, an inverted index is created. It maps each word to rows or positions where it appears. When a word is searched, the rows/documents are ranked based on its appearance frequencies or a similar measure.
4.3 Machine Learning Based Optimization

It was often mentioned that several machine learning optimization techniques are not yet reliably efficient enough for production application settings. But several techniques show great promise. One of these approaches is Kepler. It has several query optimization methods:

Reliance on direct measurements instead of cost based latency estimations.
Falling back to default optimizers when encountering queries that likely are not well solved using the machine learning based optimizer.
Focusing on training to improve parametrized queries. Parametrized queries have similar SQL structures but different parameters. This gives the machine learning model a better probability to recognize patterns. In contrast, training the model on a wide variety of SQL structures may be costly and can result in slow learning.

Industry Applications
Advancements made in query processing and optimization have been shown to bring improvements, especially in the industries that make use of big data. Some of the major applications include:

Faster analytics in retail: Retailers such as Walmart and Target quickly analyze data related to customer purchases. This in turn helps them make inventory management and marketing decisions.
Recommendation Systems: Platforms such as Netflix and Spotify benefit from quicker data analysis to suggest content to watch or listen to.
Cross cloud data analysis: Platforms including Snowflake and Databricks allow businesses to run queries across across different cloud environments.
Real time processing: Especially in the finance sector, the availability of current market data can be critical. Faster query processing often helps such industries be more profitable.
Social Media: Faster databases would enable quicker updates and interactions in real time. Notifications, feeds, and ad personalization could be delivered almost instantly, improving engagement.
Conclusion

This research explored the advancements in query processing and optimization techniques, revealing several advancements and applications.

Generally, the techniques take advantage of unique properties to bring better efficiency. For example, bitmap indexing relies on columns having low cardinality, broadcast hash join relies on one table being much smaller than the other during joins, and adaptive query optimization relies on optimizations available in mid execution. Therefore the general trend is that most techniques try to find optimizations situationally instead of bringing efficiency at all times. We believe this trend shows us that more specialized technical advances are yet to come, and better applications to the industry are yet to follow.

Overall, some of the main advancements made in query processing and optimization include distributed query processing, adaptive query execution, federated query processing, automatic indexing, enhanced indexing, and machine learning based query optimization.


